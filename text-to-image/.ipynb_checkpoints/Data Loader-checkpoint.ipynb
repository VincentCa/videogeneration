{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/kmotwani/Desktop/Me/Education/Courses/APCOMP 209B/text-to-image-master/tensorlayer/visualize.py:6: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-14102c3dd303>\", line 2, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 72, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n",
      "/anaconda3/lib/python3.6/site-packages/skimage/viewer/utils/core.py:10: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warn(\"Recommended matplotlib backend is `Agg` for full \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import tqdm\n",
    "import operator\n",
    "import os\n",
    "import os.path\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from imgpy import Img\n",
    "import pickle\n",
    "from skimage import io\n",
    "import csv\n",
    "import re\n",
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "import scipy\n",
    "from scipy import misc\n",
    "from keras import regularizers\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM, RepeatVector\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import glob\n",
    "import math\n",
    "import keras\n",
    "from utils import *\n",
    "import tensorlayer as tl\n",
    "import nltk\n",
    "\n",
    "\n",
    "from skimage.viewer import ImageViewer\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import utils\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts loaded: 4881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>File</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a man is in a concert singing</td>\n",
       "      <td>tumblr_ncxq06FwqF1sxw8kro1_250.jpg</td>\n",
       "      <td>[[[222, 222, 222], [222, 222, 222], [220, 220,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a man is hugging a woman that</td>\n",
       "      <td>tumblr_n9ssinMtQk1qlzevso1_500.jpg</td>\n",
       "      <td>[[[6, 7, 2], [7, 8, 3], [7, 8, 3], [6, 7, 2], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a man is smiling and laughing at</td>\n",
       "      <td>tumblr_m8ct3raoXa1qbyofmo1_500.jpg</td>\n",
       "      <td>[[[101, 85, 88], [101, 85, 88], [101, 85, 88],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a man is grimacing and looks pained.</td>\n",
       "      <td>tumblr_nr7xcx4fuI1usie9co1_500.jpg</td>\n",
       "      <td>[[[57, 52, 49], [111, 101, 100], [60, 46, 45],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a man is trying to take his</td>\n",
       "      <td>tumblr_n9s1duyPAa1slj978o1_400.jpg</td>\n",
       "      <td>[[[246, 242, 239], [133, 129, 126], [249, 245,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Caption                                File  \\\n",
       "0         a man is in a concert singing  tumblr_ncxq06FwqF1sxw8kro1_250.jpg   \n",
       "1         a man is hugging a woman that  tumblr_n9ssinMtQk1qlzevso1_500.jpg   \n",
       "2      a man is smiling and laughing at  tumblr_m8ct3raoXa1qbyofmo1_500.jpg   \n",
       "3  a man is grimacing and looks pained.  tumblr_nr7xcx4fuI1usie9co1_500.jpg   \n",
       "4           a man is trying to take his  tumblr_n9s1duyPAa1slj978o1_400.jpg   \n",
       "\n",
       "                                               Image  \n",
       "0  [[[222, 222, 222], [222, 222, 222], [220, 220,...  \n",
       "1  [[[6, 7, 2], [7, 8, 3], [7, 8, 3], [6, 7, 2], ...  \n",
       "2  [[[101, 85, 88], [101, 85, 88], [101, 85, 88],...  \n",
       "3  [[[57, 52, 49], [111, 101, 100], [60, 46, 45],...  \n",
       "4  [[[246, 242, 239], [133, 129, 126], [249, 245,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Helper Function to get images from train path\n",
    "def get_posts(path):\n",
    "    posts = []\n",
    "    for j in glob.glob(path + '/*.jpg'):\n",
    "        temp_dict = {}\n",
    "        img = image.load_img(j)\n",
    "        with open(j[:-4]+'.txt', encoding=\"utf-8\") as f:\n",
    "            content = f.readlines()\n",
    "            caption = ' '.join([x.strip() for x in content])\n",
    "        temp_dict['File'] = j.split('/')[-1]\n",
    "        temp_dict['Image'] = np.array(img)\n",
    "        temp_dict['Caption'] = caption\n",
    "        posts.append(temp_dict)\n",
    "    print(\"Number of posts loaded:\", len(posts))\n",
    "    return pd.DataFrame(posts)\n",
    "\n",
    "df = get_posts('/Users/kmotwani/Desktop/Me/Education/Courses/APCOMP 209B/Dataset_Walking/')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Total Dataset - No Null\n",
    "use_df = df\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(use_df)) < 0.7\n",
    "total_data_train = use_df[msk]\n",
    "total_data_test = use_df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [TL] Creating vocabulary.\n",
      "    Total words: 1804\n",
      "    Words in vocabulary: 1805\n",
      "    Wrote vocabulary file: vocab.txt\n",
      "INFO:tensorflow:Initializing vocabulary from file: vocab.txt\n",
      "  [TL] Vocabulary from vocab.txt : <S> </S> <UNK>\n",
      "    vocabulary with 1806 words (includes start_word, end_word, unk_word)\n",
      "      start_id: 4\n",
      "      end_id: 5\n",
      "      unk_id: 1805\n",
      "      pad_id: 0\n"
     ]
    }
   ],
   "source": [
    "#Generate Vocabulary\n",
    "captions = []\n",
    "do = df['Caption'].apply(lambda x: captions.append(tl.nlp.process_sentence(preprocess_caption(x), start_word=\"<S>\", end_word=\"</S>\")))\n",
    "do = tl.nlp.create_vocab(captions, word_counts_output_file='vocab.txt', min_word_count=1)\n",
    "vocab = tl.nlp.Vocabulary('vocab.txt', start_word=\"<S>\", end_word=\"</S>\", unk_word=\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Caption Dictionary\n",
    "caption_train_dict = {}\n",
    "for ind, i in enumerate(total_data_train['Caption']):\n",
    "    caption_train_dict[ind] = preprocess_caption(i)\n",
    "\n",
    "#Get Caption ID's\n",
    "captions_train_ids = []\n",
    "tmp = caption_train_dict.items()\n",
    "for key, value in tmp:\n",
    "    captions_train_ids.append([vocab.word_to_id(word) for word in nltk.tokenize.word_tokenize(value)] + [vocab.end_id])\n",
    "captions_train_ids = np.asarray(captions_train_ids)\n",
    "\n",
    "#Get Images\n",
    "images_train = []\n",
    "do = total_data_train['Image'].apply(lambda x: images_train.append(tl.prepro.imresize(x, size=[64, 64])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Caption Dictionary for Test\n",
    "caption_test_dict = {}\n",
    "for ind, i in enumerate(total_data_test['Caption']):\n",
    "    caption_test_dict[ind] = preprocess_caption(i)\n",
    "\n",
    "#Get Caption ID's\n",
    "captions_test_ids = []\n",
    "tmp = caption_test_dict.items()\n",
    "for key, value in tmp:\n",
    "    captions_test_ids.append([vocab.word_to_id(word) for word in nltk.tokenize.word_tokenize(value)] + [vocab.end_id])\n",
    "captions_test_ids = np.asarray(captions_test_ids)\n",
    "\n",
    "#Get Images\n",
    "images_test = []\n",
    "do = total_data_test['Image'].apply(lambda x: images_test.append(tl.prepro.imresize(x, size=[64, 64])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize Images to 256x256 in Train\n",
    "images_train_256 = []\n",
    "do = total_data_train['Image'].apply(lambda x: images_train_256.append(tl.prepro.imresize(x, size=[256, 256])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize Images to 256x256 in Test\n",
    "images_test_256 = []\n",
    "do = total_data_test['Image'].apply(lambda x: images_test_256.append(tl.prepro.imresize(x, size=[256, 256])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define lengths\n",
    "n_images_train = len(images_train)\n",
    "n_images_test = len(images_test)\n",
    "n_captions_train = len(captions_train_ids)\n",
    "n_captions_test = len(captions_test_ids)\n",
    "n_captions_per_image = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_all(targets, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(targets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all(vocab, '_vocab.pickle')\n",
    "save_all((images_train_256, images_train), '_image_train.pickle')\n",
    "save_all((images_test_256, images_test), '_image_test.pickle')\n",
    "save_all((n_captions_train, n_captions_test, n_captions_per_image, n_images_train, n_images_test), '_n.pickle')\n",
    "save_all((captions_train_ids, captions_test_ids), '_caption.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
